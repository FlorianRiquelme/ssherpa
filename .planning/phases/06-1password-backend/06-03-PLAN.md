---
phase: 06-1password-backend
plan: 03
type: tdd
wave: 2
depends_on: ["06-01"]
files_modified:
  - internal/backend/onepassword/status.go
  - internal/backend/onepassword/status_test.go
  - internal/backend/onepassword/poller.go
  - internal/backend/onepassword/poller_test.go
autonomous: true

must_haves:
  truths:
    - "Backend reports availability status (Available, Locked, Unavailable)"
    - "Background poller detects when 1Password becomes available mid-session"
    - "When 1Password is unavailable, backend serves cached servers from TOML"
    - "Polling interval is 5 seconds by default, configurable via environment variable"
    - "Poller stops cleanly on backend Close()"
  artifacts:
    - path: "internal/backend/onepassword/status.go"
      provides: "Backend status types and status-aware server listing"
      contains: "BackendStatus"
    - path: "internal/backend/onepassword/poller.go"
      provides: "Background availability polling with auto-recovery"
      exports: ["Poller", "NewPoller"]
  key_links:
    - from: "internal/backend/onepassword/poller.go"
      to: "internal/backend/onepassword/backend.go"
      via: "polls backend for availability, triggers sync on recovery"
      pattern: "b\\.syncFromOnePassword"
    - from: "internal/backend/onepassword/status.go"
      to: "internal/sync/toml_cache.go"
      via: "loads cached servers when 1Password unavailable"
      pattern: "sync\\.ReadTOMLCache"
---

<objective>
Implement offline fallback and availability polling: status tracking, background poller that detects when 1Password becomes available/unavailable mid-session, and cache-based fallback serving.

Purpose: Users should never be blocked from using sshjesus because 1Password is locked/unavailable. The tool must gracefully fall back to cached data and auto-recover when 1Password becomes available.

Output: Status-aware backend with background poller, tested with mock client simulating lock/unlock/unavailable scenarios.
</objective>

<execution_context>
@/Users/florianriquelme/.claude/get-shit-done/workflows/execute-plan.md
@/Users/florianriquelme/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/06-1password-backend/06-RESEARCH.md
@.planning/phases/06-1password-backend/06-01-SUMMARY.md
@internal/backend/onepassword/backend.go
@internal/backend/onepassword/client.go
@internal/sync/toml_cache.go
</context>

<tasks>

<task type="auto">
  <name>Task 1: Backend status types and status-aware server listing</name>
  <files>
    internal/backend/onepassword/status.go
    internal/backend/onepassword/status_test.go
  </files>
  <action>
**Create `internal/backend/onepassword/status.go`:**

Define status enum:
```go
type BackendStatus int

const (
    StatusUnknown     BackendStatus = iota
    StatusAvailable                        // 1Password is unlocked and responsive
    StatusLocked                           // 1Password app is running but locked
    StatusUnavailable                      // 1Password app not running or SDK error
)

func (s BackendStatus) String() string { ... }
```

Add status tracking to Backend (extend the struct from Plan 01):
```go
// Add to Backend struct:
//   status     BackendStatus
//   statusMu   sync.RWMutex
//   cachePath  string         // Path to TOML cache for fallback

func (b *Backend) GetStatus() BackendStatus { ... }
func (b *Backend) setStatus(s BackendStatus) { ... }
```

Implement `SyncFromOnePassword(ctx context.Context) error`:
- Try to list vaults via client (lightweight health check)
- On error: inspect error type for session expired (locked) vs other (unavailable)
  - Use a specific error message or type check. The SDK returns different errors for "desktop app locked" vs "app not running". Check error string for "session expired" or "desktop" keywords, or use `errors.As` if SDK provides typed errors.
  - Set status to StatusLocked or StatusUnavailable accordingly
  - Return error
- On success: fetch all tagged servers, update cache, set status to StatusAvailable
- Write to TOML cache after successful sync (for offline fallback)

Implement `LoadFromCache() error`:
- Read TOML cache via `sync.ReadTOMLCache(b.cachePath)`
- Populate `b.servers` with cached data
- This is called when 1Password is unavailable on startup

Implement status-aware `ListServers`:
- If status is Available: return live data (already cached from last sync)
- If status is Locked/Unavailable: return cached data (loaded from TOML on startup)
- If no cached data available: return empty slice (not an error — just nothing to show)

**TDD tests** (`status_test.go`):
- RED: `TestSyncFromOnePassword_Success` — mock client returns vaults+items -> status becomes Available, servers populated
- RED: `TestSyncFromOnePassword_Locked` — mock client returns session error -> status becomes Locked
- RED: `TestSyncFromOnePassword_Unavailable` — mock client returns generic error -> status becomes Unavailable
- RED: `TestLoadFromCache` — write test TOML cache, load it -> servers match
- RED: `TestListServers_Unavailable_UsesCachedData` — sync fails, load from cache -> ListServers returns cached servers
- GREEN: Implement to pass
  </action>
  <verify>
Run `go test ./internal/backend/onepassword/... -v -run TestSync` — all sync tests pass.
Run `go test ./internal/backend/onepassword/... -v -run TestLoad` — cache loading works.
Run `go test ./internal/backend/onepassword/... -v -run TestListServers_Unavailable` — fallback works.
  </verify>
  <done>
Backend tracks status (Available/Locked/Unavailable). Sync updates cache on success. ListServers returns cached data when 1Password unavailable. Status changes are thread-safe.
  </done>
</task>

<task type="auto">
  <name>Task 2: Background availability poller with auto-recovery</name>
  <files>
    internal/backend/onepassword/poller.go
    internal/backend/onepassword/poller_test.go
  </files>
  <action>
**Create `internal/backend/onepassword/poller.go`:**

```go
type Poller struct {
    backend  *Backend
    interval time.Duration
    ticker   *time.Ticker
    stopCh   chan struct{}
    onChange func(BackendStatus) // Callback when status changes (for TUI notification)
}
```

`NewPoller(backend *Backend, interval time.Duration, onChange func(BackendStatus)) *Poller`:
- Default interval: 5 seconds
- Check `SSHJESUS_1PASSWORD_POLL_INTERVAL` env var to override (parse as time.Duration)
- onChange callback is optional (nil = no callback)

`Start()`:
- Start ticker goroutine
- On each tick:
  1. Call `b.SyncFromOnePassword(ctx)` with 5-second timeout context
  2. Compare new status with previous status
  3. If status changed:
     - Log the transition (e.g., "1Password status: Unavailable -> Available")
     - Call onChange callback with new status (if non-nil)
     - If transitioning TO Available: the sync already populated servers
     - If transitioning FROM Available: servers are still cached, just status changes
- Debounce: if last write was < 10 seconds ago, skip sync (prevents sync loop after user edits)

`Stop()`:
- Stop ticker
- Close stopCh
- Blocks until goroutine exits (use sync.WaitGroup)

Add to Backend:
- `poller *Poller` field
- `StartPolling(interval time.Duration, onChange func(BackendStatus))` — creates and starts poller
- Update `Close()` to stop poller before closing client

Also add `LastWriteTime` tracking to prevent sync loops:
- `lastWrite time.Time` field on Backend
- Updated by CreateServer/UpdateServer/DeleteServer
- Poller checks: if `time.Since(b.lastWrite) < 10*time.Second`, skip this tick

**TDD tests** (`poller_test.go`):
- Use short polling interval (100ms) in tests for speed
- RED: `TestPoller_DetectsAvailability` — mock client starts failing then succeeds -> onChange called with StatusAvailable
- RED: `TestPoller_DetectsUnavailability` — mock client starts working then fails -> onChange called with StatusUnavailable
- RED: `TestPoller_StopsCleanly` — start poller, stop it, verify goroutine exits (no leaked goroutines)
- RED: `TestPoller_SkipsSyncAfterRecentWrite` — set lastWrite to now, verify sync is skipped (mock client not called)
- RED: `TestPoller_ConfigurableInterval` — set env var, verify interval is respected
- GREEN: Implement to pass

For the "leaked goroutine" test, use a counter or WaitGroup to verify the polling goroutine has stopped after `Stop()` returns.
  </action>
  <verify>
Run `go test ./internal/backend/onepassword/... -v -run TestPoller` — all poller tests pass.
Run `go test -race ./internal/backend/onepassword/...` — no race conditions.
  </verify>
  <done>
Background poller detects availability changes with configurable interval. Auto-recovery triggers sync when 1Password becomes available. Write debounce prevents sync loops. Poller stops cleanly without leaked goroutines. Thread-safe with no race conditions.
  </done>
</task>

</tasks>

<verification>
1. `go test ./internal/backend/onepassword/... -v -count=1` — all tests pass
2. `go test -race ./internal/backend/onepassword/...` — no race conditions
3. `go build ./...` — entire project compiles
4. Status transitions are logged and callbacks fire
5. Cache fallback works when 1Password unavailable
</verification>

<success_criteria>
- Backend correctly reports Available/Locked/Unavailable status
- Background poller detects status transitions within polling interval
- Auto-recovery loads fresh servers when 1Password becomes available
- Cache fallback serves previously-synced servers when offline
- Write debounce prevents sync loops after user edits
- Poller stops cleanly without goroutine leaks
- No race conditions under `-race` flag
</success_criteria>

<output>
After completion, create `.planning/phases/06-1password-backend/06-03-SUMMARY.md`
</output>
